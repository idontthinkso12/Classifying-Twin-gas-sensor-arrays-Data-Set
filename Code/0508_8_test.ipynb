{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Test the logistic regression classifier\n",
    "2. Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import Dataset_prep_yb as dp_yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\575\\gas_project\\code\\Py11\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\575\\gas_project\\code\\Py11\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\575\\gas_project\\code\\Py11\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\575\\gas_project\\code\\Py11\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.6: 0.8522, 0.5: 0.8386, 0.4: 0.8458, 0.3: 0.8579, 0.2: 0.8898, 0.1: 0.8594}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\575\\gas_project\\code\\Py11\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_data_path = f'./data/AK/X_data_op1.txt'\n",
    "y_data_path = './data/y_data_10_Half.txt'\n",
    "\n",
    "X, y = dp_yb.load_trainXy(X_data_path, y_data_path)\n",
    "\n",
    "test_size_proportions = [0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "res = {}\n",
    "for i in range(6):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_proportions[i])\n",
    "    cls1 = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
    "    \n",
    "    cls1.fit(X_train, y_train)\n",
    "    score = cls1.score(X_test, y_test)\n",
    "    res[test_size_proportions[i]] = round(score,4)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.6: 0.8707, 0.5: 0.8924, 0.4: 0.913, 0.3: 0.8526, 0.2: 0.8976, 0.1: 0.9375}\n"
     ]
    }
   ],
   "source": [
    "X_data_path = f'./data/AK/X_data_op2.txt'\n",
    "y_data_path = './data/y_data_10_Half.txt'\n",
    "\n",
    "X, y = dp_yb.load_trainXy(X_data_path, y_data_path)\n",
    "\n",
    "test_size_proportions = [0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "res = {}\n",
    "for i in range(6):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_proportions[i])\n",
    "    cls2 = LogisticRegression(max_iter=3000)\n",
    "    \n",
    "    cls2.fit(X_train, y_train)\n",
    "    score = cls2.score(X_test, y_test)\n",
    "    res[test_size_proportions[i]] = round(score,4)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.6: 0.942, 0.5: 0.9589, 0.4: 0.9447, 0.3: 0.9684, 0.2: 0.9764, 0.1: 0.9688}\n"
     ]
    }
   ],
   "source": [
    "X_data_path = f'./data/AK/X_data_op3.txt'\n",
    "y_data_path = './data/y_data_10_Half.txt'\n",
    "\n",
    "X, y = dp_yb.load_trainXy(X_data_path, y_data_path)\n",
    "\n",
    "test_size_proportions = [0.6, 0.5, 0.4, 0.3, 0.2, 0.1]\n",
    "res = {}\n",
    "for i in range(6):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_proportions[i])\n",
    "    cls3 = LogisticRegression(solver='lbfgs', max_iter=200)\n",
    "    cls3.fit(X_train, y_train)\n",
    "    score = cls3.score(X_test, y_test)\n",
    "    res[test_size_proportions[i]] = round(score,4)\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename2 = './saved_models/8/Logistic_op2.sav'\n",
    "pickle.dump(cls2, open(filename2,'wb'))\n",
    "\n",
    "filename3 = './saved_models/8/Logistic_op3.sav'\n",
    "pickle.dump(cls3, open(filename3,'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "model1 = pickle.load(open(filename2,'rb'))\n",
    "model2 = pickle.load(open(filename3,'rb'))\n",
    "\n",
    "model_coeficients1 = model1.coef_\n",
    "model_intercept1 = model1.intercept_\n",
    "\n",
    "model_coeficients2 = model2.coef_\n",
    "model_intercept2 = model2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.61318024 -1.51951389  1.07570403  0.70287702 -0.30401349  0.62616087\n",
      "  -0.38251275  0.45868306]\n",
      " [-0.47519703  0.36867674  0.74342827 -2.65763186  3.34037128 -1.03775693\n",
      "  -0.91347073  0.61147558]\n",
      " [-0.11495193  0.22239161 -0.63922379  0.46923062 -0.97027463  0.05125071\n",
      "   0.89578473  0.02525933]\n",
      " [ 1.20332919  0.92844554 -1.17990851  1.48552423 -2.06608316  0.36034535\n",
      "   0.40019875 -1.09541797]]\n",
      "[-0.99829749 -1.06392822 -0.08098097  2.14320667]\n"
     ]
    }
   ],
   "source": [
    "print(model_coeficients1)\n",
    "print(model_intercept1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.95214888 -0.4001824  -1.28542757 -0.89447982 -0.06309417 -0.98290776\n",
      "   0.24860825 -1.12810469]\n",
      " [ 0.58015171 -1.69110466 -0.77068368  0.73178558 -0.08011296  4.17844246\n",
      "  -1.54597575  0.25419034]\n",
      " [-0.42451341  0.66325837  0.62916873  0.3884338   0.09836984  0.17671509\n",
      "  -0.21623488  0.45996738]\n",
      " [-1.10778719  1.42802869  1.42694252 -0.22573957  0.04483729 -3.3722498\n",
      "   1.51360237  0.41394697]]\n",
      "[-4.50098815 -3.08026881  5.45359694  2.12766002]\n"
     ]
    }
   ],
   "source": [
    "print(model_coeficients2)\n",
    "print(model_intercept2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
